# -*- coding: utf-8 -*-
"""GloVe_embeddings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TgeTNn4ndQJKGh3akH7aFuJx0aCeAd2H
"""

import pandas as pd
import pickle
from tqdm import tqdm
import numpy as np
import os

proj_dir='~/probing_codeBERT/'



data_df = pd.read_json('./test.jsonl', lines=True)

def make_glove_dict():
  embeddings_dict = {}
  with open('./glove.6B.300d.txt', 'r') as f:
    for line in tqdm(f,total=400001):
        values = line.split()
        word = values[0]
        vector = np.asarray(values[1:], "float32")
        embeddings_dict[word] = vector
    
    return embeddings_dict

req_dict=make_glove_dict()

def get_glove_mean_embedding(sentence):
  unseen_words=[]
  li=[]
  for word in sentence.split():
    word=word.split('.')[0].lower()
    try:
      embed=req_dict[word]
      li.append(embed)
    except:
      unseen_words.append(word)
      continue
  mean_embeddings=np.mean(li,axis=0)
  return mean_embeddings,unseen_words


def get_all_glove_embeddings():
  unseen_words_li=[]
  ser=data_df["docstring_summary"]
  for index, sentence in tqdm(enumerate(ser),total=len(ser)):
    embed,unseen_words=get_glove_mean_embedding(sentence)
    unseen_words_li.extend(unseen_words)
    # print(embed)
    with open(f'./Glove_embeddings/line_{index}.npy', 'wb') as f:
      np.save(f, embed)
  
  return unseen_words_li

unseen_words_li=get_all_glove_embeddings()

print(len(unseen_words_li))






